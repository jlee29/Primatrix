{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# let's not pollute this blog post with warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skvideo.io as skv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "run = '-benchmark-lrcn-micro'\n",
    "labelpath = os.path.join('train_labels.csv')\n",
    "train_labels = pd.read_csv(labelpath, index_col='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>cattle</th>\n",
       "      <th>chimpanzee</th>\n",
       "      <th>elephant</th>\n",
       "      <th>forest buffalo</th>\n",
       "      <th>gorilla</th>\n",
       "      <th>hippopotamus</th>\n",
       "      <th>human</th>\n",
       "      <th>hyena</th>\n",
       "      <th>...</th>\n",
       "      <th>other (primate)</th>\n",
       "      <th>pangolin</th>\n",
       "      <th>porcupine</th>\n",
       "      <th>reptile</th>\n",
       "      <th>rodent</th>\n",
       "      <th>small antelope</th>\n",
       "      <th>small cat</th>\n",
       "      <th>wild dog</th>\n",
       "      <th>duiker</th>\n",
       "      <th>hog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000libDc84.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003TeGtbkD.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006jFoesFi.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008uxqP8IN.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0094UxdyyZ.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                bird  blank  cattle  chimpanzee  elephant  forest buffalo  \\\n",
       "filename                                                                    \n",
       "000libDc84.mp4   0.0    1.0     0.0         0.0       0.0             0.0   \n",
       "003TeGtbkD.mp4   0.0    1.0     0.0         0.0       0.0             0.0   \n",
       "006jFoesFi.mp4   0.0    0.0     0.0         0.0       0.0             0.0   \n",
       "008uxqP8IN.mp4   0.0    0.0     0.0         0.0       0.0             0.0   \n",
       "0094UxdyyZ.mp4   0.0    0.0     0.0         0.0       0.0             0.0   \n",
       "\n",
       "                gorilla  hippopotamus  human  hyena ...   other (primate)  \\\n",
       "filename                                            ...                     \n",
       "000libDc84.mp4      0.0           0.0    0.0    0.0 ...               0.0   \n",
       "003TeGtbkD.mp4      0.0           0.0    0.0    0.0 ...               0.0   \n",
       "006jFoesFi.mp4      0.0           0.0    0.0    0.0 ...               0.0   \n",
       "008uxqP8IN.mp4      0.0           0.0    0.0    0.0 ...               0.0   \n",
       "0094UxdyyZ.mp4      0.0           0.0    0.0    0.0 ...               1.0   \n",
       "\n",
       "                pangolin  porcupine  reptile  rodent  small antelope  \\\n",
       "filename                                                               \n",
       "000libDc84.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "003TeGtbkD.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "006jFoesFi.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "008uxqP8IN.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "0094UxdyyZ.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "\n",
       "                small cat  wild dog  duiker  hog  \n",
       "filename                                          \n",
       "000libDc84.mp4        0.0       0.0     0.0  0.0  \n",
       "003TeGtbkD.mp4        0.0       0.0     0.0  0.0  \n",
       "006jFoesFi.mp4        0.0       0.0     1.0  0.0  \n",
       "008uxqP8IN.mp4        0.0       0.0     0.0  1.0  \n",
       "0094UxdyyZ.mp4        0.0       0.0     0.0  0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 204130 entries, 000libDc84.mp4 to zzzu2lK8bC.mp4\n",
      "Data columns (total 24 columns):\n",
      "bird                   204130 non-null float64\n",
      "blank                  204130 non-null float64\n",
      "cattle                 204130 non-null float64\n",
      "chimpanzee             204130 non-null float64\n",
      "elephant               204130 non-null float64\n",
      "forest buffalo         204130 non-null float64\n",
      "gorilla                204130 non-null float64\n",
      "hippopotamus           204130 non-null float64\n",
      "human                  204130 non-null float64\n",
      "hyena                  204130 non-null float64\n",
      "large ungulate         204130 non-null float64\n",
      "leopard                204130 non-null float64\n",
      "lion                   204130 non-null float64\n",
      "other (non-primate)    204130 non-null float64\n",
      "other (primate)        204130 non-null float64\n",
      "pangolin               204130 non-null float64\n",
      "porcupine              204130 non-null float64\n",
      "reptile                204130 non-null float64\n",
      "rodent                 204130 non-null float64\n",
      "small antelope         204130 non-null float64\n",
      "small cat              204130 non-null float64\n",
      "wild dog               204130 non-null float64\n",
      "duiker                 204130 non-null float64\n",
      "hog                    204130 non-null float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 38.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blank                  122270.0\n",
       "duiker                  21601.0\n",
       "other (primate)         20453.0\n",
       "human                   20034.0\n",
       "chimpanzee               5045.0\n",
       "hog                      4650.0\n",
       "rodent                   2911.0\n",
       "bird                     2386.0\n",
       "other (non-primate)      1883.0\n",
       "elephant                 1085.0\n",
       "porcupine                 569.0\n",
       "cattle                    372.0\n",
       "small antelope            273.0\n",
       "large ungulate            224.0\n",
       "leopard                   209.0\n",
       "hippopotamus              175.0\n",
       "gorilla                   174.0\n",
       "small cat                  79.0\n",
       "pangolin                   63.0\n",
       "wild dog                   21.0\n",
       "hyena                      10.0\n",
       "forest buffalo              9.0\n",
       "reptile                     8.0\n",
       "lion                        2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_labels.sum(axis=1) > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from primatrix_dataset_utils import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapath = os.path.join('.')\n",
    "whichset = run.split('-')[-1]\n",
    "redframes = whichset == 'nano'\n",
    "data = Dataset(datapath=datapath, \n",
    "               dataset_type=whichset,\n",
    "               reduce_frames=redframes, \n",
    "               batch_size=32, \n",
    "               test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142891"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61239"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 30, 64, 64, 1)     4         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 60, 60, 64)    1664      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 30, 30, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 28, 28, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 14, 14, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 14, 14, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 12, 12, 256)   295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 6, 6, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 6, 6, 256)     1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 30, 4, 4, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 30, 2, 2, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 30, 2, 2, 512)     2048      \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 30, 1, 1, 1024)    2098176   \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 30, 1024)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 256)           1311744   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                82176     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                1560      \n",
      "=================================================================\n",
      "Total params: 5,048,348\n",
      "Trainable params: 5,046,426\n",
      "Non-trainable params: 1,922\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# add three time-distributed convolutional layers for feature extraction\n",
    "model.add(BatchNormalization(input_shape=(data.num_frames, data.width, data.height, 1)))\n",
    "model.add(TimeDistributed(Conv2D(64, (5, 5), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(Conv2D(1024, (2,2), activation='relu')))\n",
    "\n",
    "\n",
    "# extract features and dropout \n",
    "model.add(TimeDistributed(Flatten()))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "# input to LSTM\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.0))\n",
    "model.add(LSTM(64, return_sequences=False, dropout=0.0))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# classifier with sigmoid activation for multilabel\n",
    "model.add(Dense(data.num_classes, activation='sigmoid'))\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.001, decay=0.0)\n",
    "\n",
    "# compile the model with binary_crossentropy loss for multilabel\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "model_name = 'model' + run + '.h5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# look at the params before training\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6000\n",
      "222/223 [============================>.] - ETA: 7s - loss: 0.1408 Epoch 00000: val_loss improved from inf to 0.09298, saving model to model-benchmark-lrcn-micro.h5\n",
      "223/223 [==============================] - 2342s - loss: 0.1407 - val_loss: 0.0930\n",
      "Epoch 2/6000\n",
      "222/223 [============================>.] - ETA: 7s - loss: 0.1022 Epoch 00001: val_loss did not improve\n",
      "223/223 [==============================] - 2285s - loss: 0.1023 - val_loss: 0.0939\n",
      "Epoch 3/6000\n",
      "222/223 [============================>.] - ETA: 7s - loss: 0.0987 Epoch 00002: val_loss improved from 0.09298 to 0.09250, saving model to model-benchmark-lrcn-micro.h5\n",
      "223/223 [==============================] - 2298s - loss: 0.0987 - val_loss: 0.0925\n",
      "Epoch 4/6000\n",
      "222/223 [============================>.] - ETA: 7s - loss: 0.0957 "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    data.batches(), \n",
    "    steps_per_epoch=int(data.num_batches/20),                  # data.num_batches to train on full set \n",
    "    epochs=6000, \n",
    "    validation_data=data.val_batches(), \n",
    "    validation_steps=int(data.num_val_batches/20),                  # data.num_val_batches to validate on full set\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "from keras.models import load_model\n",
    "\n",
    "trained_model = load_model(model_name)\n",
    "\n",
    "# generate predictions\n",
    "for batch_num in tqdm(range(data.num_test_batches), total=data.num_test_batches):\n",
    "\n",
    "    # make predictions on batch\n",
    "    results = trained_model.predict_proba(next(data.test_batches()), \n",
    "                                          batch_size=data.batch_size, \n",
    "                                          verbose=0)\n",
    "\n",
    "    # update submission format dataframe stored in dataset object\n",
    "    data.update_predictions(results)          \n",
    "    \n",
    "data.predictions.to_csv(os.path.join(data.datapath, 'predictions' + run + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head -n 5 ./predictions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
