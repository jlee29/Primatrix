{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# let's not pollute this blog post with warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skvideo.io as skv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "run = '-inception-lrcn-color-micro'\n",
    "labelpath = os.path.join('train_labels.csv')\n",
    "train_labels = pd.read_csv(labelpath, index_col='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_labels.sum(axis=1) > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from primatrix_dataset_utils import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapath = os.path.join('.')\n",
    "whichset = run.split('-')[-1]\n",
    "redframes = whichset == 'nano'\n",
    "data = Dataset(datapath=datapath, \n",
    "               dataset_type=whichset,\n",
    "               reduce_frames=redframes, \n",
    "               batch_size=32, \n",
    "               test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.models import Model\n",
    "# Backend\n",
    "from keras import backend as K\n",
    "# Utils\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "# Implements the Inception Network v3 (http://arxiv.org/pdf/1602.07261v1.pdf) in Keras. #\n",
    "#########################################################################################\n",
    "\n",
    "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
    "              padding='same', strides=(1, 1), use_bias=False):\n",
    "    \"\"\"\n",
    "    Utility function to apply conv + BN. \n",
    "    (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
    "    \"\"\"\n",
    "    channel_axis = -1\n",
    "    x = TimeDistributed(Convolution2D(nb_filter, (num_row, num_col),\n",
    "                      strides=strides,\n",
    "                      padding=padding,\n",
    "                      use_bias=use_bias,\n",
    "                      kernel_initializer=initializers.he_normal()))(x)\n",
    "    x = TimeDistributed(BatchNormalization(axis=channel_axis, scale=False))(x)\n",
    "    x = TimeDistributed(Activation('relu'))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_a(input):\n",
    "    # 30 x 7 x 7 x 256\n",
    "    channel_axis = -1\n",
    "    \n",
    "    \n",
    "    branch_0 = conv2d_bn(input, 64, 1, 1)\n",
    "    # 30 x 7 x 7 x 96\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
    "    # 30 x 7 x 7 x 64\n",
    "    \n",
    "    branch_1 = conv2d_bn(branch_1, 64, 3, 3)\n",
    "    # 30 x 7 x 7 x 96\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
    "    # 30 x 7 x 7 x 64\n",
    "    branch_2 = conv2d_bn(branch_2, 64, 3, 3)\n",
    "    # 30 x 7 x 7 x 96\n",
    "    branch_2 = conv2d_bn(branch_2, 64, 3, 3)\n",
    "    # 30 x 7 x 7 x 96\n",
    "\n",
    "    branch_3 = TimeDistributed(AveragePooling2D((3,3), strides=(1,1), padding='same'))(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 64, 1, 1)\n",
    "    # 30 x 7 x 7 x 96\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    # 30 x 7 x 7 x 256\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_a(input):\n",
    "    # 30 x 7 x 7 x 256\n",
    "    channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 128, 3, 3, strides=(2,2), padding='valid')\n",
    "    # 30 x 3 x 3 x 128\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 96, 1, 1)\n",
    "    # 30 x 7 x 7 x 192\n",
    "    branch_1 = conv2d_bn(branch_1, 112, 3, 3)\n",
    "    # 30 x 7 x 7 x 224\n",
    "    branch_1 = conv2d_bn(branch_1, 128, 3, 3, strides=(2,2), padding='valid')\n",
    "    # 30 x 3 x 3 x 128\n",
    "\n",
    "    branch_2 = TimeDistributed(MaxPooling2D((3,3), strides=(2,2), padding='valid'))(input)\n",
    "     # 30 x 3 x 3 x 256\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_b(input):\n",
    "    channel_axis = -1\n",
    "    #3 x 3 x 512\n",
    "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 96, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 112, 1, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 128, 3, 1)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 96, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 112, 1, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 112, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 128, 1, 3)\n",
    "\n",
    "    branch_3 = TimeDistributed(AveragePooling2D((3,3), strides=(1,1), padding='same'))(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 64, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_b(input):\n",
    "    channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(3, 3), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 1, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 3, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(3,3), padding='valid')\n",
    "\n",
    "    branch_2 = TimeDistributed(MaxPooling2D((3, 3), strides=(3, 3), padding='valid'))(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_c(input):\n",
    "    channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_10 = conv2d_bn(branch_1, 128, 1, 3)\n",
    "    branch_11 = conv2d_bn(branch_1, 128, 3, 1)\n",
    "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
    "\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 1, 3)\n",
    "    branch_20 = conv2d_bn(branch_2, 128, 1, 3)\n",
    "    branch_21 = conv2d_bn(branch_2, 128, 3, 1)\n",
    "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
    "\n",
    "    branch_3 = TimeDistributed(AveragePooling2D((3, 3), strides=(1, 1), padding='same'))(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_v3_base(input):\n",
    "    channel_axis = -1\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
    "    # Input Shape is 30 x 64 x 64 x 3\n",
    "    net = conv2d_bn(input, 32, 4, 4, strides=(2,2), padding='valid')\n",
    "    # 30 x 31 x 31 x 32\n",
    "    net = conv2d_bn(net, 32, 3, 3)\n",
    "    # 30 x 31 x 31 x 32\n",
    "    net = conv2d_bn(net, 64, 3, 3)\n",
    "    # 30 x 31 x 31 x 64\n",
    "\n",
    "    \n",
    "    branch_0 = TimeDistributed(MaxPooling2D((3,3), strides=(2,2), padding='valid'))(net)\n",
    "    # 30 x 15 x 15 x 64\n",
    "    \n",
    "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
    "    # 30 x 15 x 15 x 96\n",
    "    \n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "    # 30 x 15 x 15 x 160\n",
    "    \n",
    "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
    "    # 30 x 15 x 15 x 64\n",
    "    branch_0 = conv2d_bn(branch_0, 64, 3, 3)\n",
    "    # 30 x 15 x 15 x 64\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
    "    # 30 x 15 x 15 x 64    \n",
    "    branch_1 = conv2d_bn(branch_1, 64, 1, 5)\n",
    "    # 30 x 15 x 15 x 64    \n",
    "    branch_1 = conv2d_bn(branch_1, 64, 5, 1)\n",
    "    # 30 x 15 x 15 x 64    \n",
    "    branch_1 = conv2d_bn(branch_1, 64, 3, 3)\n",
    "    # 30 x 15 x 15 x 64\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "    # 30 x 15 x 15 x 128\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 128, 3, 3, strides=(2,2), padding='valid')\n",
    "    # 30 x 7 x 7 x 128\n",
    "    \n",
    "    branch_1 = TimeDistributed(MaxPooling2D((3,3), strides=(2,2), padding='valid'))(net)\n",
    "    # 30 x 7 x 7 x 128\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "    # 30 x 7 x 7 x 256\n",
    "\n",
    "    \n",
    "    # 4 x Inception-A blocks\n",
    "    for idx in range(4):\n",
    "        net = block_inception_a(net)\n",
    "\n",
    "    # 30 x 7 x 7 x 256\n",
    "    # Reduction-A block\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 3 x 3 x 512\n",
    "    # 7 x Inception-B blocks\n",
    "    for idx in range(7):\n",
    "        net = block_inception_b(net)\n",
    "\n",
    "    # 3 x 3 x 512\n",
    "    # Reduction-B block\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 1 x 1 x 1024\n",
    "    # 3 x Inception-C blocks\n",
    "    #for idx in range(3):\n",
    "    #    net = block_inception_c(net)\n",
    "    # 1 x 1 x 1024\n",
    "    return net\n",
    "\n",
    "\n",
    "def inception_v3(num_classes=24, dropout_keep_prob=0.5, include_top=True):\n",
    "    '''\n",
    "    Creates the inception v3 network\n",
    "    Args:\n",
    "    \tnum_classes: number of classes\n",
    "    \tdropout_keep_prob: float, the fraction to keep before final layer.\n",
    "    \n",
    "    Returns: \n",
    "    \tlogits: the logits outputs of the model.\n",
    "    '''\n",
    "\n",
    "    inputs = Input((data.num_frames, data.width, data.height, 3))\n",
    "    x = BatchNormalization(axis=-1)(inputs)\n",
    "\n",
    "    # Make inception base\n",
    "    x = inception_v3_base(x)\n",
    "\n",
    "\n",
    "    # Final pooling and prediction\n",
    "    if include_top:\n",
    "        # 30 x 1 x 1 x 1024\n",
    "        x = TimeDistributed(Flatten())(x)\n",
    "        x = LSTM(256, return_sequences=False)(x)\n",
    "        # 30 x 256\n",
    "        #x = LSTM(64, return_sequences=False)(x)\n",
    "        # 256\n",
    "        x = Dropout(dropout_keep_prob)(x)\n",
    "        \n",
    "        # 64\n",
    "        x = Dense(units=num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, x, name='inception_v3')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = inception_v3()\n",
    "\n",
    "\n",
    "# classifier with sigmoid activation for multilabel\n",
    "model.add(Dense(data.num_classes, activation='softmax'))\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.001, decay=0.0, clipnorm=5.)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=20, min_lr=0.00001, verbose=True)\n",
    "\n",
    "\n",
    "# compile the model with binary_crossentropy loss for multilabel\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "model_name = 'model' + run + '.h5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "\n",
    "# look at the params before training\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    data.batches(), \n",
    "    steps_per_epoch=int(data.num_batches/20),                  # data.num_batches to train on full set \n",
    "    epochs=6000, \n",
    "    validation_data=data.val_batches(), \n",
    "    validation_steps=int(data.num_val_batches/20),                  # data.num_val_batches to validate on full set\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "from keras.models import load_model\n",
    "\n",
    "trained_model = load_model(model_name)\n",
    "\n",
    "# generate predictions\n",
    "for batch_num in tqdm(range(data.num_test_batches), total=data.num_test_batches):\n",
    "\n",
    "    # make predictions on batch\n",
    "    results = trained_model.predict(next(data.test_batches()), \n",
    "                                          batch_size=data.batch_size, \n",
    "                                          verbose=0)\n",
    "\n",
    "    # update submission format dataframe stored in dataset object\n",
    "    data.update_predictions(results)          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.predictions.to_csv(os.path.join(data.datapath, 'predictions' + run + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
