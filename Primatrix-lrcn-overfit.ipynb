{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# let's not pollute this blog post with warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skvideo.io as skv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "run = '-mobilenet-overfit-micro'\n",
    "labelpath = os.path.join('train_labels.csv')\n",
    "train_labels = pd.read_csv(labelpath, index_col='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bird</th>\n",
       "      <th>blank</th>\n",
       "      <th>cattle</th>\n",
       "      <th>chimpanzee</th>\n",
       "      <th>elephant</th>\n",
       "      <th>forest buffalo</th>\n",
       "      <th>gorilla</th>\n",
       "      <th>hippopotamus</th>\n",
       "      <th>human</th>\n",
       "      <th>hyena</th>\n",
       "      <th>...</th>\n",
       "      <th>other (primate)</th>\n",
       "      <th>pangolin</th>\n",
       "      <th>porcupine</th>\n",
       "      <th>reptile</th>\n",
       "      <th>rodent</th>\n",
       "      <th>small antelope</th>\n",
       "      <th>small cat</th>\n",
       "      <th>wild dog</th>\n",
       "      <th>duiker</th>\n",
       "      <th>hog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000libDc84.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003TeGtbkD.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006jFoesFi.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008uxqP8IN.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0094UxdyyZ.mp4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                bird  blank  cattle  chimpanzee  elephant  forest buffalo  \\\n",
       "filename                                                                    \n",
       "000libDc84.mp4   0.0    1.0     0.0         0.0       0.0             0.0   \n",
       "003TeGtbkD.mp4   0.0    1.0     0.0         0.0       0.0             0.0   \n",
       "006jFoesFi.mp4   0.0    0.0     0.0         0.0       0.0             0.0   \n",
       "008uxqP8IN.mp4   0.0    0.0     0.0         0.0       0.0             0.0   \n",
       "0094UxdyyZ.mp4   0.0    0.0     0.0         0.0       0.0             0.0   \n",
       "\n",
       "                gorilla  hippopotamus  human  hyena ...   other (primate)  \\\n",
       "filename                                            ...                     \n",
       "000libDc84.mp4      0.0           0.0    0.0    0.0 ...               0.0   \n",
       "003TeGtbkD.mp4      0.0           0.0    0.0    0.0 ...               0.0   \n",
       "006jFoesFi.mp4      0.0           0.0    0.0    0.0 ...               0.0   \n",
       "008uxqP8IN.mp4      0.0           0.0    0.0    0.0 ...               0.0   \n",
       "0094UxdyyZ.mp4      0.0           0.0    0.0    0.0 ...               1.0   \n",
       "\n",
       "                pangolin  porcupine  reptile  rodent  small antelope  \\\n",
       "filename                                                               \n",
       "000libDc84.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "003TeGtbkD.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "006jFoesFi.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "008uxqP8IN.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "0094UxdyyZ.mp4       0.0        0.0      0.0     0.0             0.0   \n",
       "\n",
       "                small cat  wild dog  duiker  hog  \n",
       "filename                                          \n",
       "000libDc84.mp4        0.0       0.0     0.0  0.0  \n",
       "003TeGtbkD.mp4        0.0       0.0     0.0  0.0  \n",
       "006jFoesFi.mp4        0.0       0.0     1.0  0.0  \n",
       "008uxqP8IN.mp4        0.0       0.0     0.0  1.0  \n",
       "0094UxdyyZ.mp4        0.0       0.0     0.0  0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 204130 entries, 000libDc84.mp4 to zzzu2lK8bC.mp4\n",
      "Data columns (total 24 columns):\n",
      "bird                   204130 non-null float64\n",
      "blank                  204130 non-null float64\n",
      "cattle                 204130 non-null float64\n",
      "chimpanzee             204130 non-null float64\n",
      "elephant               204130 non-null float64\n",
      "forest buffalo         204130 non-null float64\n",
      "gorilla                204130 non-null float64\n",
      "hippopotamus           204130 non-null float64\n",
      "human                  204130 non-null float64\n",
      "hyena                  204130 non-null float64\n",
      "large ungulate         204130 non-null float64\n",
      "leopard                204130 non-null float64\n",
      "lion                   204130 non-null float64\n",
      "other (non-primate)    204130 non-null float64\n",
      "other (primate)        204130 non-null float64\n",
      "pangolin               204130 non-null float64\n",
      "porcupine              204130 non-null float64\n",
      "reptile                204130 non-null float64\n",
      "rodent                 204130 non-null float64\n",
      "small antelope         204130 non-null float64\n",
      "small cat              204130 non-null float64\n",
      "wild dog               204130 non-null float64\n",
      "duiker                 204130 non-null float64\n",
      "hog                    204130 non-null float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 38.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blank                  122270.0\n",
       "duiker                  21601.0\n",
       "other (primate)         20453.0\n",
       "human                   20034.0\n",
       "chimpanzee               5045.0\n",
       "hog                      4650.0\n",
       "rodent                   2911.0\n",
       "bird                     2386.0\n",
       "other (non-primate)      1883.0\n",
       "elephant                 1085.0\n",
       "porcupine                 569.0\n",
       "cattle                    372.0\n",
       "small antelope            273.0\n",
       "large ungulate            224.0\n",
       "leopard                   209.0\n",
       "hippopotamus              175.0\n",
       "gorilla                   174.0\n",
       "small cat                  79.0\n",
       "pangolin                   63.0\n",
       "wild dog                   21.0\n",
       "hyena                      10.0\n",
       "forest buffalo              9.0\n",
       "reptile                     8.0\n",
       "lion                        2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_labels.sum(axis=1) > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from primatrix_dataset_utils_overfit import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000libDc84.mp4' '003TeGtbkD.mp4' '006jFoesFi.mp4' '008uxqP8IN.mp4'\n",
      " '0094UxdyyZ.mp4' '009Bm4R6ke.mp4' '00Cw71Q7mp.mp4' '00DAdApXV5.mp4'\n",
      " '00EcW4Z4Iy.mp4' '00GcOZpJIr.mp4' '00GnlMwGm0.mp4' '00IBE38OWj.mp4'\n",
      " '00JRe5ZGg7.mp4' '00JiLU8uBe.mp4' '00KLCPKkFC.mp4' '00KPNQcfrv.mp4'\n",
      " '00M4lnQV16.mp4' '00MqYQh31d.mp4' '00PkBYslCh.mp4' '00QuBrCWLL.mp4'\n",
      " '00SDd7SSFf.mp4' '00UejWIbCh.mp4' '00UhxKIrHG.mp4' '00VE5WBpwZ.mp4'\n",
      " '00YqPojkvr.mp4' '00ZthvsuWW.mp4' '00aoQMT1EU.mp4' '00b8iiWvAJ.mp4'\n",
      " '00e8EQeEu5.mp4' '00eLJaaQOF.mp4' '00fGoKSs4A.mp4' '00iW7nBPxy.mp4']\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "datapath = os.path.join('.')\n",
    "whichset = run.split('-')[-1]\n",
    "redframes = whichset == 'nano'\n",
    "data = Dataset(datapath=datapath, \n",
    "               dataset_type='micro-overfit',\n",
    "               reduce_frames=False, \n",
    "               batch_size=32, \n",
    "               test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, GlobalAveragePooling2D, Activation, Dense, Input\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers import concatenate\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras import constraints\n",
    "from keras.models import Model\n",
    "# Backend\n",
    "from keras import backend as K\n",
    "# Utils\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import conv_utils\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "class DepthwiseConv2D(Conv2D):\n",
    "    \"\"\"Depthwise separable 2D convolution.\n",
    "    Depthwise Separable convolutions consists in performing\n",
    "    just the first step in a depthwise spatial convolution\n",
    "    (which acts on each input channel separately).\n",
    "    The `depth_multiplier` argument controls how many\n",
    "    output channels are generated per input channel in the depthwise step.\n",
    "    # Arguments\n",
    "        kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "            Specifying any stride value != 1 is incompatible with specifying\n",
    "            any `dilation_rate` value != 1.\n",
    "        padding: one of `'valid'` or `'same'` (case-insensitive).\n",
    "        depth_multiplier: The number of depthwise convolution output channels\n",
    "            for each input channel.\n",
    "            The total number of depthwise convolution output\n",
    "            channels will be equal to `filters_in * depth_multiplier`.\n",
    "        data_format: A string,\n",
    "            one of `channels_last` (default) or `channels_first`.\n",
    "            The ordering of the dimensions in the inputs.\n",
    "            `channels_last` corresponds to inputs with shape\n",
    "            `(batch, height, width, channels)` while `channels_first`\n",
    "            corresponds to inputs with shape\n",
    "            `(batch, channels, height, width)`.\n",
    "            It defaults to the `image_data_format` value found in your\n",
    "            Keras config file at `~/.keras/keras.json`.\n",
    "            If you never set it, then it will be 'channels_last'.\n",
    "        activation: Activation function to use\n",
    "            (see [activations](../activations.md)).\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. 'linear' activation: `a(x) = x`).\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "        depthwise_initializer: Initializer for the depthwise kernel matrix\n",
    "            (see [initializers](../initializers.md)).\n",
    "        bias_initializer: Initializer for the bias vector\n",
    "            (see [initializers](../initializers.md)).\n",
    "        depthwise_regularizer: Regularizer function applied to\n",
    "            the depthwise kernel matrix\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        bias_regularizer: Regularizer function applied to the bias vector\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        activity_regularizer: Regularizer function applied to\n",
    "            the output of the layer (its 'activation').\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        depthwise_constraint: Constraint function applied to\n",
    "            the depthwise kernel matrix\n",
    "            (see [constraints](../constraints.md)).\n",
    "        bias_constraint: Constraint function applied to the bias vector\n",
    "            (see [constraints](../constraints.md)).\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `[batch, channels, rows, cols]` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `[batch, rows, cols, channels]` if data_format='channels_last'.\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `[batch, filters, new_rows, new_cols]` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `[batch, new_rows, new_cols, filters]` if data_format='channels_last'.\n",
    "        `rows` and `cols` values might have changed due to padding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 depth_multiplier=1,\n",
    "                 data_format=None,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 depthwise_initializer='he_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 depthwise_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 depthwise_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(DepthwiseConv2D, self).__init__(\n",
    "            filters=None,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.depthwise_initializer = initializers.get(depthwise_initializer)\n",
    "        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n",
    "        self.depthwise_constraint = constraints.get(depthwise_constraint)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) < 4:\n",
    "            raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n",
    "                             'Received input shape:', str(input_shape))\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = 3\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs to '\n",
    "                             '`DepthwiseConv2D` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = int(input_shape[channel_axis])\n",
    "        depthwise_kernel_shape = (self.kernel_size[0],\n",
    "                                  self.kernel_size[1],\n",
    "                                  input_dim,\n",
    "                                  self.depth_multiplier)\n",
    "\n",
    "        self.depthwise_kernel = self.add_weight(\n",
    "            shape=depthwise_kernel_shape,\n",
    "            initializer=self.depthwise_initializer,\n",
    "            name='depthwise_kernel',\n",
    "            regularizer=self.depthwise_regularizer,\n",
    "            constraint=self.depthwise_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        outputs = K.depthwise_conv2d(\n",
    "            inputs,\n",
    "            self.depthwise_kernel,\n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "            dilation_rate=self.dilation_rate,\n",
    "            data_format=self.data_format)\n",
    "\n",
    "        if self.bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            rows = input_shape[2]\n",
    "            cols = input_shape[3]\n",
    "            out_filters = input_shape[1] * self.depth_multiplier\n",
    "        elif self.data_format == 'channels_last':\n",
    "            rows = input_shape[1]\n",
    "            cols = input_shape[2]\n",
    "            out_filters = input_shape[3] * self.depth_multiplier\n",
    "\n",
    "        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n",
    "                                             self.padding,\n",
    "                                             self.strides[0])\n",
    "        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n",
    "                                             self.padding,\n",
    "                                             self.strides[1])\n",
    "\n",
    "        if self.data_format == 'channels_first':\n",
    "            return (input_shape[0], out_filters, rows, cols)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            return (input_shape[0], rows, cols, out_filters)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DepthwiseConv2D, self).get_config()\n",
    "        config.pop('filters')\n",
    "        config.pop('kernel_initializer')\n",
    "        config.pop('kernel_regularizer')\n",
    "        config.pop('kernel_constraint')\n",
    "        config['depth_multiplier'] = self.depth_multiplier\n",
    "        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n",
    "        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n",
    "        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n",
    "        return config\n",
    "\n",
    "\n",
    "def MobileNet(input_shape=None,\n",
    "              alpha=1.0,\n",
    "              depth_multiplier=1,\n",
    "              dropout=0.,\n",
    "              include_top=True,\n",
    "              input_tensor=None,\n",
    "              pooling=None,\n",
    "              classes=24):\n",
    "    \"\"\"Instantiates the MobileNet architecture.\n",
    "    Note that only TensorFlow is supported for now,\n",
    "    therefore it only works with the data format\n",
    "    `image_data_format='channels_last'` in your Keras config\n",
    "    at `~/.keras/keras.json`.\n",
    "    To load a MobileNet model via `load_model`, import the custom\n",
    "    objects `relu6` and `DepthwiseConv2D` and pass them to the\n",
    "    `custom_objects` parameter.\n",
    "    E.g.\n",
    "    model = load_model('mobilenet.h5', custom_objects={\n",
    "                       'relu6': mobilenet.relu6,\n",
    "                       'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n",
    "    # Arguments\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or (3, 224, 224) (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 32.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        alpha: controls the width of the network.\n",
    "            - If `alpha` < 1.0, proportionally decreases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` > 1.0, proportionally increases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` = 1, default number of filters from the paper\n",
    "                 are used at each layer.\n",
    "        depth_multiplier: depth multiplier for depthwise convolution\n",
    "            (also called the resolution multiplier)\n",
    "        dropout: dropout rate\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor (i.e. output of\n",
    "            `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model\n",
    "                will be the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a\n",
    "                2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "        RuntimeError: If attempting to run this model with a\n",
    "            backend that does not support separable convolutions.\n",
    "    \"\"\"\n",
    "    default_size = 64\n",
    "\n",
    "    input_shape = (data.num_frames, data.width, data.height, 3)\n",
    "    row_axis, col_axis = (1, 2)\n",
    "    rows = input_shape[row_axis]\n",
    "    cols = input_shape[col_axis]\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = BatchNormalization(axis=-1)(inputs)  \n",
    "\n",
    "    x = _conv_block(x, 32, alpha, strides=(2, 2))\n",
    "    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=2)\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=4)\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=6)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=12)\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n",
    "\n",
    "    if include_top:\n",
    "        x = TimeDistributed(Flatten())(x)\n",
    "        x = LSTM(256, return_sequences=False)(x)        \n",
    "        x = Dropout(dropout)(x)        \n",
    "        x = Dense(units=classes, activation='softmax')(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, rows))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):\n",
    "    \"\"\"Adds an initial convolution layer (with batch normalization and relu6).\n",
    "    # Arguments\n",
    "        inputs: Input tensor of shape `(rows, cols, 3)`\n",
    "            (with `channels_last` data format) or\n",
    "            (3, rows, cols) (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 32.\n",
    "            E.g. `(224, 224, 3)` would be one valid value.\n",
    "        filters: Integer, the dimensionality of the output space\n",
    "            (i.e. the number output of filters in the convolution).\n",
    "        alpha: controls the width of the network.\n",
    "            - If `alpha` < 1.0, proportionally decreases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` > 1.0, proportionally increases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` = 1, default number of filters from the paper\n",
    "                 are used at each layer.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "            Specifying any stride value != 1 is incompatible with specifying\n",
    "            any `dilation_rate` value != 1.\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, channels, rows, cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
    "        `rows` and `cols` values might have changed due to stride.\n",
    "    # Returns\n",
    "        Output tensor of block.\n",
    "    \"\"\"\n",
    "    channel_axis = -1\n",
    "    filters = int(filters * alpha)\n",
    "    x = TimeDistributed(Conv2D(filters, kernel,\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=strides,\n",
    "               name='conv1',\n",
    "               kernel_initializer=initializers.he_normal()))(inputs)\n",
    "    x = TimeDistributed(BatchNormalization(axis=channel_axis, name='conv1_bn'))(x)\n",
    "    return Activation(relu6, name='conv1_relu')(x)\n",
    "\n",
    "\n",
    "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n",
    "                          depth_multiplier=1, strides=(1, 1), block_id=1):\n",
    "    \"\"\"Adds a depthwise convolution block.\n",
    "    A depthwise convolution block consists of a depthwise conv,\n",
    "    batch normalization, relu6, pointwise convolution,\n",
    "    batch normalization and relu6 activation.\n",
    "    # Arguments\n",
    "        inputs: Input tensor of shape `(rows, cols, channels)`\n",
    "            (with `channels_last` data format) or\n",
    "            (channels, rows, cols) (with `channels_first` data format).\n",
    "        pointwise_conv_filters: Integer, the dimensionality of the output space\n",
    "            (i.e. the number output of filters in the pointwise convolution).\n",
    "        alpha: controls the width of the network.\n",
    "            - If `alpha` < 1.0, proportionally decreases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` > 1.0, proportionally increases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` = 1, default number of filters from the paper\n",
    "                 are used at each layer.\n",
    "        depth_multiplier: The number of depthwise convolution output channels\n",
    "            for each input channel.\n",
    "            The total number of depthwise convolution output\n",
    "            channels will be equal to `filters_in * depth_multiplier`.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "            Specifying any stride value != 1 is incompatible with specifying\n",
    "            any `dilation_rate` value != 1.\n",
    "        block_id: Integer, a unique identification designating the block number.\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, channels, rows, cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, rows, cols, channels)` if data_format='channels_last'.\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, filters, new_rows, new_cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
    "        `rows` and `cols` values might have changed due to stride.\n",
    "    # Returns\n",
    "        Output tensor of block.\n",
    "    \"\"\"\n",
    "    channel_axis = -1\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "    x = TimeDistributed(DepthwiseConv2D((3, 3),\n",
    "                        padding='same',\n",
    "                        depth_multiplier=depth_multiplier,\n",
    "                        strides=strides,\n",
    "                        use_bias=False,\n",
    "                        name='conv_dw_%d' % block_id))(inputs)\n",
    "    x = TimeDistributed(BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id))(x)\n",
    "    x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n",
    "\n",
    "    x = TimeDistributed(Conv2D(pointwise_conv_filters, (1, 1),\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=(1, 1),\n",
    "               name='conv_pw_%d' % block_id,\n",
    "               kernel_initializer=initializers.he_normal()))(x)\n",
    "    x = TimeDistributed(BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id))(x)\n",
    "    return Activation(relu6, name='conv_pw_%d_relu' % block_id)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "#model = VGG19()\n",
    "model = MobileNet(dropout=0.2)\n",
    "\n",
    "\n",
    "# classifier with sigmoid activation for multilabel\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.001, decay=0.0, clipnorm=5.)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=20, min_lr=0.00001, verbose=True)\n",
    "\n",
    "\n",
    "# compile the model with binary_crossentropy loss for multilabel\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "model_name = 'model' + run + '.h5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "\n",
    "# look at the params before training\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 11s - loss: 0.1821\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 3s - loss: 0.1890\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 7s - loss: 0.1150\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 7s - loss: 0.1054\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 7s - loss: 0.1040\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 6s - loss: 0.0933\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 7s - loss: 0.0742\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 7s - loss: 0.0715\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 7s - loss: 0.0843\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 7s - loss: 0.0790\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 7s - loss: 0.0798\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 6s - loss: 0.0698\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 7s - loss: 0.0564\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 7s - loss: 0.0559\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 7s - loss: 0.0411\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 6s - loss: 0.0475\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 7s - loss: 0.0621\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 6s - loss: 0.0424\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 6s - loss: 0.0350\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 6s - loss: 0.0292\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 7s - loss: 0.0261\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 7s - loss: 0.0481\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 7s - loss: 0.0290\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 7s - loss: 0.0311\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 7s - loss: 0.0167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59f799fcc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### from keras.models import load_model\n",
    "#model_name = 'model' + run + '.h5'\n",
    "#model = load_model(model_name)\n",
    "#adam = keras.optimizers.Adam(lr=0.001, decay=0.0, clipnorm=5.0)\n",
    "\n",
    "#model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "#checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    data.batches(), \n",
    "    steps_per_epoch=data.num_batches,                  # data.num_batches to train on full set \n",
    "    epochs=25\n",
    ")\n",
    "#model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "#model = VGG19()\n",
    "model = MobileNet(dropout=0.2)\n",
    "\n",
    "\n",
    "# classifier with sigmoid activation for multilabel\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0003, decay=0.0, clipnorm=5.)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=20, min_lr=0.00001, verbose=True)\n",
    "\n",
    "\n",
    "# compile the model with binary_crossentropy loss for multilabel\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "model_name = 'model' + run + '.h5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 12s - loss: 0.1709\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 3s - loss: 0.1227\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 7s - loss: 0.0834\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 7s - loss: 0.0940\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 7s - loss: 0.1194\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 7s - loss: 0.0764\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 7s - loss: 0.0870\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 7s - loss: 0.1017\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 7s - loss: 0.0796\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 7s - loss: 0.0586\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 7s - loss: 0.0822\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 7s - loss: 0.0722\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 7s - loss: 0.0928\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 7s - loss: 0.0576\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 7s - loss: 0.0531\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 7s - loss: 0.0794\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 7s - loss: 0.0458\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 7s - loss: 0.0532\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 7s - loss: 0.0654\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 7s - loss: 0.0671\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 7s - loss: 0.0452\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 7s - loss: 0.0424\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 7s - loss: 0.0479\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 7s - loss: 0.0527\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 7s - loss: 0.0480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a039cae48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    data.batches(), \n",
    "    steps_per_epoch=data.num_batches,                  # data.num_batches to train on full set \n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MobileNet(dropout=0.5)\n",
    "\n",
    "\n",
    "# classifier with sigmoid activation for multilabel\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.001, decay=0.0, clipnorm=5.)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=20, min_lr=0.00001, verbose=True)\n",
    "\n",
    "\n",
    "# compile the model with binary_crossentropy loss for multilabel\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "model_name = 'model' + run + '.h5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 14s - loss: 0.1825\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 3s - loss: 0.1466\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 8s - loss: 0.1108\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 8s - loss: 0.0969\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 8s - loss: 0.0763\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 8s - loss: 0.1171\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 8s - loss: 0.1140\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 8s - loss: 0.0935\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 8s - loss: 0.0684\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 8s - loss: 0.0887\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 8s - loss: 0.0655\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 8s - loss: 0.0785\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 8s - loss: 0.0584\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 7s - loss: 0.0697\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 7s - loss: 0.0844\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 8s - loss: 0.0621\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 7s - loss: 0.0647\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 8s - loss: 0.0517\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 8s - loss: 0.0423\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 8s - loss: 0.0390\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 7s - loss: 0.0325\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 8s - loss: 0.0704\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 8s - loss: 0.0300\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 8s - loss: 0.0364\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 8s - loss: 0.0268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f596c342da0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    data.batches(), \n",
    "    steps_per_epoch=data.num_batches,                  # data.num_batches to train on full set \n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MobileNet(dropout=0.5)\n",
    "\n",
    "\n",
    "# classifier with sigmoid activation for multilabel\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0003, decay=0.0, clipnorm=5.)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=20, min_lr=0.00001, verbose=True)\n",
    "\n",
    "\n",
    "# compile the model with binary_crossentropy loss for multilabel\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "model_name = 'model' + run + '.h5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 16s - loss: 0.1779\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 2s - loss: 0.1067\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 8s - loss: 0.1025\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 8s - loss: 0.1508\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 8s - loss: 0.0808\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 8s - loss: 0.0891\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 8s - loss: 0.0876\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 8s - loss: 0.0769\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 8s - loss: 0.0778\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 8s - loss: 0.0583\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 8s - loss: 0.0857\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 8s - loss: 0.1211\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 8s - loss: 0.0718\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 8s - loss: 0.0582\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 8s - loss: 0.0672\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 8s - loss: 0.0642\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 8s - loss: 0.0568\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 8s - loss: 0.0434\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 9s - loss: 0.0665\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/skvideo/io/ffmpeg.py\", line 267, in _read_frame_data\n",
      "    assert len(arr) == framesize\n",
      "AssertionError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 568, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/home/ninja2/Primatrix/primatrix_dataset_utils_overfit.py\", line 148, in batches\n",
      "    verbose=verbose,y=y)\n",
      "  File \"/home/ninja2/Primatrix/primatrix_dataset_utils_overfit.py\", line 267, in _get_video_batch\n",
      "    video = skv.vread(filepath, as_grey=as_grey)\n",
      "  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/skvideo/io/io.py\", line 148, in vread\n",
      "    for idx, frame in enumerate(reader.nextFrame()):\n",
      "  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/skvideo/io/ffmpeg.py\", line 293, in nextFrame\n",
      "    yield self._readFrame()\n",
      "  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/skvideo/io/ffmpeg.py\", line 277, in _readFrame\n",
      "    s = self._read_frame_data()\n",
      "  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/skvideo/io/ffmpeg.py\", line 271, in _read_frame_data\n",
      "    raise RuntimeError(\"%s\" % (err1,))\n",
      "RuntimeError\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-7441dfb89f14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m,\u001b[0m                  \u001b[1;31m# data.num_batches to train on full set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    642\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    data.batches(), \n",
    "    steps_per_epoch=data.num_batches,                  # data.num_batches to train on full set \n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MobileNet(dropout=0.2)\n",
    "\n",
    "\n",
    "# classifier with sigmoid activation for multilabel\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.003, decay=0.0, clipnorm=5.)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=20, min_lr=0.00001, verbose=True)\n",
    "\n",
    "\n",
    "# compile the model with binary_crossentropy loss for multilabel\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "model_name = 'model' + run + '.h5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 17s - loss: 0.1899\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 2s - loss: 0.2098\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 9s - loss: 0.0923\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 9s - loss: 0.1083\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 9s - loss: 0.1013\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 9s - loss: 0.0829\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 9s - loss: 0.0867\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 9s - loss: 0.0972\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 9s - loss: 0.0800\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 9s - loss: 0.0943\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 9s - loss: 0.0833\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 9s - loss: 0.0862\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 9s - loss: 0.0725\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 9s - loss: 0.0595\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 9s - loss: 0.0908\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 9s - loss: 0.0589\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 9s - loss: 0.0782\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 9s - loss: 0.0794\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 9s - loss: 0.0608\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 9s - loss: 0.0706\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 9s - loss: 0.0579\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 9s - loss: 0.0830\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 9s - loss: 0.0697\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 9s - loss: 0.0617\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 9s - loss: 0.0643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5942adcef0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    data.batches(), \n",
    "    steps_per_epoch=data.num_batches,                  # data.num_batches to train on full set \n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MobileNet(dropout=0.5)\n",
    "\n",
    "\n",
    "# classifier with sigmoid activation for multilabel\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.003, decay=0.0, clipnorm=5.)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=20, min_lr=0.00001, verbose=True)\n",
    "\n",
    "\n",
    "# compile the model with binary_crossentropy loss for multilabel\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "\n",
    "model_name = 'model' + run + '.h5'\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    data.batches(), \n",
    "    steps_per_epoch=data.num_batches,                  # data.num_batches to train on full set \n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
